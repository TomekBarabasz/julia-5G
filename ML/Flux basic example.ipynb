{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7048249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "269cbea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.47805241579368496 0.9342085025027564 … 0.828099601947663 0.679295935253563; 0.47805241579368496 0.9342085025027564 … 0.828099601947663 0.679295935253563; 0.47805241579368496 0.9342085025027564 … 0.828099601947663 0.679295935253563], 3-element Fill{Float64}: entries equal to 1.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = randn(3, 5)\n",
    "b = zeros(3)\n",
    "x = rand(5)\n",
    "y(x) = sum(W * x .+ b)\n",
    "grads = gradient(()->y(x), params([W, b]))\n",
    "grads[W], grads[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf38fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 100), (2, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Dense(10, 5)\n",
    "opt = Descent(0.01)\n",
    "data, labels = rand(10, 100), fill(0.5, 2, 100)\n",
    "loss(x, y) = Flux.Losses.crossentropy(m(x), y)\n",
    "size(data),size(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "215fe024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([Float32[-0.33784732 0.2732509 … -0.4858327 -0.25094163; -0.45437732 0.15492545 … -0.44713837 0.37235707; … ; -0.5756332 0.15144192 … -0.33599365 0.39601; 0.07076791 -0.30130115 … 0.40723324 -0.41785014], Float32[0.0, 0.0, 0.0, 0.0, 0.0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b85dd342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Matrix{Int64}:\n",
       " 1  2  3\n",
       " 4  5  6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=[1 2 3;4 5 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42cf6942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c110c16",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "DimensionMismatch(\"dimensions must match: a has dims (Base.OneTo(100), Base.OneTo(10)), b has dims (Base.OneTo(100), Base.OneTo(2)), mismatch at 2\")",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch(\"dimensions must match: a has dims (Base.OneTo(100), Base.OneTo(10)), b has dims (Base.OneTo(100), Base.OneTo(2)), mismatch at 2\")",
      "",
      "Stacktrace:",
      " [1] promote_shape",
      "   @ ./indices.jl:178 [inlined]",
      " [2] _promote_tuple_shape",
      "   @ ./iterators.jl:334 [inlined]",
      " [3] axes(z::Base.Iterators.Zip{Tuple{LinearAlgebra.Adjoint{Float64, Matrix{Float64}}, LinearAlgebra.Adjoint{Float64, Matrix{Float64}}}})",
      "   @ Base.Iterators ./iterators.jl:331",
      " [4] _array_for",
      "   @ ./array.jl:670 [inlined]",
      " [5] collect(itr::Base.Generator{Base.Iterators.Zip{Tuple{LinearAlgebra.Adjoint{Float64, Matrix{Float64}}, LinearAlgebra.Adjoint{Float64, Matrix{Float64}}}}, typeof(identity)})",
      "   @ Base ./array.jl:683",
      " [6] top-level scope",
      "   @ In[15]:2",
      " [7] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [8] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "#loss(data,labels)\n",
    "[cf for cf in zip(data',labels')]\n",
    "#loss.([cf for cf in zip(data,labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a954fc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching loss(::Matrix{Float64})\n\u001b[0mClosest candidates are:\n\u001b[0m  loss(::Any, \u001b[91m::Any\u001b[39m) at In[4]:4",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching loss(::Matrix{Float64})\n\u001b[0mClosest candidates are:\n\u001b[0m  loss(::Any, \u001b[91m::Any\u001b[39m) at In[4]:4",
      "",
      "Stacktrace:",
      "  [1] macro expansion",
      "    @ ~/.julia/packages/Zygote/i1R8y/src/compiler/interface2.jl:0 [inlined]",
      "  [2] _pullback(ctx::Zygote.Context, f::typeof(loss), args::Matrix{Float64})",
      "    @ Zygote ~/.julia/packages/Zygote/i1R8y/src/compiler/interface2.jl:9",
      "  [3] _apply(::Function, ::Vararg{Any, N} where N)",
      "    @ Core ./boot.jl:804",
      "  [4] adjoint",
      "    @ ~/.julia/packages/Zygote/i1R8y/src/lib/lib.jl:191 [inlined]",
      "  [5] _pullback",
      "    @ ~/.julia/packages/ZygoteRules/OjfTt/src/adjoint.jl:57 [inlined]",
      "  [6] _pullback",
      "    @ ~/.julia/packages/Flux/qp1gc/src/optimise/train.jl:102 [inlined]",
      "  [7] _pullback(::Zygote.Context, ::Flux.Optimise.var\"#39#45\"{typeof(loss), Matrix{Float64}})",
      "    @ Zygote ~/.julia/packages/Zygote/i1R8y/src/compiler/interface2.jl:0",
      "  [8] pullback(f::Function, ps::Zygote.Params)",
      "    @ Zygote ~/.julia/packages/Zygote/i1R8y/src/compiler/interface.jl:250",
      "  [9] gradient(f::Function, args::Zygote.Params)",
      "    @ Zygote ~/.julia/packages/Zygote/i1R8y/src/compiler/interface.jl:58",
      " [10] macro expansion",
      "    @ ~/.julia/packages/Flux/qp1gc/src/optimise/train.jl:101 [inlined]",
      " [11] macro expansion",
      "    @ ~/.julia/packages/Juno/n6wyj/src/progress.jl:134 [inlined]",
      " [12] train!(loss::Function, ps::Zygote.Params, data::Tuple{Matrix{Float64}, Matrix{Float64}}, opt::Descent; cb::Flux.Optimise.var\"#40#46\")",
      "    @ Flux.Optimise ~/.julia/packages/Flux/qp1gc/src/optimise/train.jl:99",
      " [13] train!(loss::Function, ps::Zygote.Params, data::Tuple{Matrix{Float64}, Matrix{Float64}}, opt::Descent)",
      "    @ Flux.Optimise ~/.julia/packages/Flux/qp1gc/src/optimise/train.jl:97",
      " [14] top-level scope",
      "    @ In[18]:1",
      " [15] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [16] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "Flux.train!(loss, params(m), (data,labels), opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a952d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
